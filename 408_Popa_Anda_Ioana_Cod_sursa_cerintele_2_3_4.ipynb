{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424f0738-4f9a-4691-82bb-78c217aa5bb3",
   "metadata": {},
   "source": [
    "# Proiect de Analiză a Recenziilor Spotify\n",
    "## Student: Popa Anda-Ioana\n",
    "### Grupa: 408"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee3f73-f9eb-4db4-8755-0e459c0de2fa",
   "metadata": {},
   "source": [
    "# Cuprins\n",
    "1. [Introducere](#introducere)\n",
    "2. [Implementarea de script-uri Spark pentru procesarea datelor](#implementarea)\n",
    "3. [Aplicarea a cel puțin două metode ML](#aplicarea)\n",
    "4. [Utilizarea unui Data Pipeline](#utilizarea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a6027-c9f6-4b76-b718-903a19d829b4",
   "metadata": {},
   "source": [
    "# 1. Introducere <a name=\"introducere\"></a>\r\n",
    "\r\n",
    "## a. Prezentarea succintă a setului de date\r\n",
    "\r\n",
    "Setul de date ales pentru acest proiect este intitulat **Spotify Reviews** și poate fi descărcat de pe Kaggle, accesând următorul link: [aici](https://www.kaggle.com/datasets/ashishkumarak/spotify-reviews-playstore-daily-update?resource=download&select=spotify_reviews.csv). Acesta conține recenzii ale utilizatorilor pentru aplicația Spotify, preluate de pe Google Play Store. Datele sunt actualizate zilnic și includ diverse atribute relevante pentru evaluarea feedback-ului utilizatorilor.\r\n",
    "\r\n",
    "Structura setului de date include următoarele coloane principale:\r\n",
    "- **reviewId**: Un identificator unic pentru fiecare recenzie.\r\n",
    "- **userName**: Numele utilizatorului care a scris recenzia.\r\n",
    "- **userImage**: URL-ul imaginii de profil a utilizatorului.\r\n",
    "- **content**: Textul recenziei.\r\n",
    "- **score**: Scorul oferit aplicației (de la 1 la 5 stele).\r\n",
    "- **thumbsUpCount**: Numărul de utilizatori care au găsit recenzia utilă.\r\n",
    "- **reviewCreatedVersion**: Versiunea aplicației la momentul recenziei.\r\n",
    "- **at**: Data la care a fost scrisă recenzia.\r\n",
    "- **replyContent**: Răspunsul dezvoltatorului la recenzie (dacă există).\r\n",
    "- **repliedAt**: Data la care dezvoltatorul a răspuns recenziei.\r\n",
    "\r\n",
    "Acest set de date este valoros pentru analizarea părerii utilizatorilor față de aplicația Spotify, identificarea principalelor probleme întâmpinate de utilizatori, și evaluarea impactului actualizărilor aplicației asupra experienței utilizatorilor.\r\n",
    "\r\n",
    "## b. Enunțarea obiectivelor\r\n",
    "\r\n",
    "Scopul acestui proiect este de a efectua o analiză cuprinzătoare a recenziilor utilizatorilor pentru aplicația Spotify, folosind Apache Spark pentru procesarea și transformarea datelor, precum și metode de învățare automată pentru clasificarea impresiilor și alte analize relevante. Proiectul va fi structurat în mai multe etape, fiecare având obiective specifice, după cum urmează:\r\n",
    "\r\n",
    "### 1. Preprocesarea și Curățarea Datelor:\r\n",
    "- Curățarea textului recenziilor pentru a elimina caracterele speciale și zgomotul.\r\n",
    "- Tratarea valorilor lipsă și a datelor eronate.\r\n",
    "- Conversia datelor într-un format adecvat pentru analize ulterioare.\r\n",
    "\r\n",
    "### 2. Explorarea și Vizualizarea Datelor:\r\n",
    "- Explorarea statistică a setului de date pentru a înțelege distribuția scorurilor, frecvența recenziilor pe diverse versiuni ale aplicației, și alte aspecte relevante.\r\n",
    "- Vizualizarea datelor folosind grafice și diagrame pentru a identifica tendințele și modelele emergente.\r\n",
    "\r\n",
    "### 3. Analiza Părerii:\r\n",
    "- Utilizarea Spark MLlib pentru a aplica metode de învățare automată, cum ar fi clasificarea sentimentelor (pozitiv, negativ, neutru) în recenziile utilizatorilor.\r\n",
    "- Evaluarea performanței modelelor utilizate și interpretarea rezultatelor obținute.\r\n",
    "\r\n",
    "### 4. Identificarea Temelor Principale:\r\n",
    "- Aplicarea tehnicilor de grupare și agregare pentru a identifica temele principale și problemele recurente menționate în recenzii.\r\n",
    "- Utilizarea Spark SQL și DataFrames pentru a efectua aceste analize.\r\n",
    "\r\n",
    "### 5. Crearea unui Data Pipeline:\r\n",
    "- Implementarea unui pipeline de date pentru a automatiza procesul de preprocesare, analiză și clasificare a recenziilor.\r\n",
    "- Asigurarea scalabilității și eficienței pipeline-ului pentru a putea gestiona volume mari de date.\r\n",
    "\r\n",
    "Prin atingerea acestor obiective, proiectul va oferi o perspectivă detaliată asupra feedback-ului utilizatorilor pentru aplicația Spotify, identificând aspectele pozitive și negative și oferind recomandări pentru îmbunătățirea experienței utilizatorilor.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fec922-e22c-47ea-be25-0f47fd548f05",
   "metadata": {},
   "source": [
    "# 2. Implementarea de script-uri Spark pentru procesarea datelor <a name=\"implementarea\"></a>\r\n",
    "\r\n",
    "Pentru acest proiect, voi folosi Apache Spark pentru a prelucra, curăța și transforma datele. Vom utiliza DataFrames și Spark SQL pentru a efectua operații de grupare și agregare. \r\n",
    "\r\n",
    "## 2.1 Configurarea Mediului Spark\r\n",
    "\r\n",
    "Prima etapă este configurarea mediului Spark și încărcarea setului de date.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d00f443-5db4-43b5-9fa2-cbcbc8f010d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+\n",
      "|            reviewId|            userName|             content|score|thumbsUpCount|reviewCreatedVersion|                 at|appVersion|\n",
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+\n",
      "|437314fe-1b1d-435...|           Rajib Das|           It's good|    4|            0|                NULL|2024-05-09 16:28:13|      NULL|\n",
      "|4933ad2c-c70a-4a8...|Mihaela Claudia N...|I love this app s...|    5|            0|          8.9.38.494|2024-05-09 16:27:18|8.9.38.494|\n",
      "|1ab275fb-59bf-42c...|     JONATHAN GRACIA|             Perfect|    5|            0|          8.9.36.616|2024-05-09 16:27:03|8.9.36.616|\n",
      "|b38406eb-7b11-4ce...|          Cam Rempel|Best all around m...|    5|            0|          8.9.38.494|2024-05-09 16:26:19|8.9.38.494|\n",
      "|7be7999d-4cb6-47b...|Your clowness (He...|Are y'all fr gate...|    1|            0|          8.9.38.494|2024-05-09 16:26:14|8.9.38.494|\n",
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importarea bibliotecilor necesare \n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import col, regexp_replace, to_timestamp, avg, count, desc \n",
    "\n",
    "# Inițializarea unei sesiuni Spark \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spotify Reviews Analysis\") \\\n",
    "    .getOrCreate() \n",
    "\n",
    "# Încărcarea setului de date \n",
    "file_path = \"D:\\Master anul 1 sem 2\\Big Data\\spotify_reviews.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Vizualizarea primelor rânduri ale DataFrame-ului \n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a114a7b-f446-4f08-a979-746d0546bcf1",
   "metadata": {},
   "source": [
    "## 2.2 Preprocesarea și Curățarea Datelor\r\n",
    "Pentru preprocesarea datelor, voi curăța textul recenziilor, voi trata valorile lipsă și voi converti coloanele la tipurile de date adecvate.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0017e053-0cff-4e19-b123-5f72c5f97cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+--------------------+-------------------+\n",
      "|            reviewId|            userName|             content|score|thumbsUpCount|reviewCreatedVersion|                 at|appVersion|       clean_content|        review_date|\n",
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+--------------------+-------------------+\n",
      "|437314fe-1b1d-435...|           Rajib Das|           It's good|    4|            0|                NULL|2024-05-09 16:28:13|      NULL|            Its good|2024-05-09 16:28:13|\n",
      "|4933ad2c-c70a-4a8...|Mihaela Claudia N...|I love this app s...|    5|            0|          8.9.38.494|2024-05-09 16:27:18|8.9.38.494|I love this app s...|2024-05-09 16:27:18|\n",
      "|1ab275fb-59bf-42c...|     JONATHAN GRACIA|             Perfect|    5|            0|          8.9.36.616|2024-05-09 16:27:03|8.9.36.616|             Perfect|2024-05-09 16:27:03|\n",
      "|b38406eb-7b11-4ce...|          Cam Rempel|Best all around m...|    5|            0|          8.9.38.494|2024-05-09 16:26:19|8.9.38.494|Best all around m...|2024-05-09 16:26:19|\n",
      "|7be7999d-4cb6-47b...|Your clowness (He...|Are y'all fr gate...|    1|            0|          8.9.38.494|2024-05-09 16:26:14|8.9.38.494|Are yall fr gatek...|2024-05-09 16:26:14|\n",
      "+--------------------+--------------------+--------------------+-----+-------------+--------------------+-------------------+----------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eliminarea valorilor lipsă \n",
    "df_clean = df.na.drop(subset=[\"content\", \"score\", \"at\"]) \n",
    "# Curățarea textului recenziilor pentru a elimina caracterele speciale \n",
    "df_clean = df_clean.withColumn(\"clean_content\", regexp_replace(col(\"content\"), \"[^a-zA-Z0-9\\s]\", \"\")) \n",
    "# Conversia coloanei 'at' la tipul de date Data \n",
    "df_clean = df_clean.withColumn(\"review_date\", to_timestamp(col(\"at\"), \"yyyy-MM-dd HH:mm:ss\")) \n",
    "# Vizualizarea primelor rânduri după curățare \n",
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae6947-a78d-4399-8484-614a04864572",
   "metadata": {},
   "source": [
    "## 2.3 Explorarea și Vizualizarea Datelor\r\n",
    "Voi explora setul de date pentru a înțelege distribuția scorurilor și alte statistici descriptive.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7973bb17-30a0-4fe5-b30a-1fa24edcf1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               score|count|\n",
      "+--------------------+-----+\n",
      "|         \"\"Artists\"\"|    1|\n",
      "|     \"\"Dismiss\"\" and|    1|\n",
      "| \"\"Events\"\" etc. ...|    1|\n",
      "| \"\"I know what wi...|    1|\n",
      "| \"\"Recently Liste...|    1|\n",
      "| \"\"Spotify offline\"\"|    1|\n",
      "|          \"\"albums\"\"|    1|\n",
      "| \"\"listen to two ...|    1|\n",
      "| \"\"music\"\" can't ...|    1|\n",
      "|    \"\"new playlist\"\"|    1|\n",
      "| \"\"no user found ...|    1|\n",
      "|         \"\"ooh ahh\"\"|    1|\n",
      "|      \"\"the pocket\"\"|    1|\n",
      "| \"\"wait\"\" or \"\"se...|    1|\n",
      "| \"\"wven\"\" of I br...|    1|\n",
      "|          $10 a YEAR|    1|\n",
      "| & can't play oth...|    1|\n",
      "| & everything els...|    1|\n",
      "| & now it's stuck...|    1|\n",
      "| (which will how ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+------------------+\n",
      "|reviewCreatedVersion|     average_score|\n",
      "+--------------------+------------------+\n",
      "|           8.9.8.417|               5.0|\n",
      "|          8.4.72.842|               5.0|\n",
      "|          8.4.36.321|               5.0|\n",
      "|          8.5.11.582|               5.0|\n",
      "|          8.4.35.152|               4.5|\n",
      "|           3.3.0.988|               4.0|\n",
      "|          8.4.72.845| 3.878651685393258|\n",
      "|         8.4.85.1006|3.8666666666666667|\n",
      "|          8.9.36.616| 3.720576873551378|\n",
      "|          8.9.38.494| 3.686725663716814|\n",
      "|          8.4.74.463|3.6346153846153846|\n",
      "|          8.4.81.558|3.5348837209302326|\n",
      "|          8.4.50.644|               3.5|\n",
      "|          8.8.94.566|               3.5|\n",
      "|          8.9.24.632|               3.5|\n",
      "|           8.3.0.681|               3.5|\n",
      "|          8.6.52.916|               3.5|\n",
      "|          8.4.80.793|               3.4|\n",
      "|             1.2.5.3|3.3333333333333335|\n",
      "|          8.4.82.664|3.2816901408450705|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcularea distribuției scorurilor \n",
    "score_distribution = df_clean.groupBy(\"score\").count().orderBy(\"score\") \n",
    "# Afișarea distribuției scorurilor \n",
    "score_distribution.show() \n",
    "# Calcularea scorului mediu pentru fiecare versiune a aplicației \n",
    "average_score_per_version = df_clean.groupBy(\"reviewCreatedVersion\").agg(avg(\"score\").alias(\"average_score\")) \n",
    "# Afișarea scorului mediu pe versiuni \n",
    "average_score_per_version.orderBy(desc(\"average_score\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6bba7-5448-4e4a-9c3c-1d4dbfbbdf4f",
   "metadata": {},
   "source": [
    "## 2.4 Analiza Sentimentului\r\n",
    "Voi aplica metode de învățare automată pentru a clasifica sentimentele recenziilor. În această etapă, voi pregăti datele pentru modelare.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3359eaae-a969-47fa-86ef-d67a0c32d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+-----+\n",
      "|       clean_content|         probability|prediction|label|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "|I love using spot...|[0.11314725935005...|       1.0|    1|\n",
      "|I love my premium...|[0.23074400965238...|       1.0|    1|\n",
      "|The fact that the...|[0.98632583844751...|       0.0|    0|\n",
      "|Huge issue with t...|[0.15691094324704...|       1.0|    1|\n",
      "|After several upd...|[0.71191757889934...|       0.0|    0|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF \n",
    "from pyspark.ml.classification import LogisticRegression \n",
    "from pyspark.ml import Pipeline \n",
    "# Tokenizarea textului recenziilor \n",
    "tokenizer = Tokenizer(inputCol=\"clean_content\", outputCol=\"words\")\n",
    "# Eliminarea cuvintelor comune (stop words)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Convertirea textului în vectori de frecvență a termenilor \n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "# Calcularea TF-IDF \n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "# Configurarea etichetei pentru clasificare\n",
    "df_clean = df_clean.withColumn(\"label\", (col(\"score\") >= 4).cast(\"int\"))\n",
    "# Eliminarea valorilor lipsă sau NaN în coloana \"label\" și \"clean_content\"\n",
    "df_clean = df_clean.na.drop(subset=[\"label\", \"clean_content\"])\n",
    "# Crearea modelului de regresie logistică\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "# Crearea pipeline-ului\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "# Împărțirea setului de date în date de antrenament și date de test\n",
    "(trainingData, testData) = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
    "# Antrenarea modelului\n",
    "model = pipeline.fit(trainingData)\n",
    "# Evaluarea modelului pe datele de test\n",
    "predictions = model.transform(testData)\n",
    "# Afișarea rezultatelor\n",
    "predictions.select(\"clean_content\", \"probability\", \"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542f084-7363-490a-a4fe-763f83985f52",
   "metadata": {},
   "source": [
    "## 2.5 Grupări și Agregări de Date\r\n",
    "Voi efectua operații de grupare și agregare pentru a identifica principalele teme și probleme din recenzii.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab87db4-9449-4452-bc8d-874e6ca4d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|score|useful_reviews|\n",
      "+-----+--------------+\n",
      "|    1|         33213|\n",
      "|    5|         13256|\n",
      "|    2|         12902|\n",
      "|    3|         11322|\n",
      "|    4|          9230|\n",
      "+-----+--------------+\n",
      "\n",
      "+--------------------+------------------+\n",
      "|reviewCreatedVersion|     average_score|\n",
      "+--------------------+------------------+\n",
      "|           8.9.8.417|               5.0|\n",
      "|          8.4.72.842|               5.0|\n",
      "|          8.4.36.321|               5.0|\n",
      "|          8.5.11.582|               5.0|\n",
      "|          8.4.35.152|               4.5|\n",
      "|           3.3.0.988|               4.0|\n",
      "|          8.4.72.845| 3.878651685393258|\n",
      "|         8.4.85.1006|3.8666666666666667|\n",
      "|          8.9.36.616| 3.720576873551378|\n",
      "|          8.9.38.494| 3.686725663716814|\n",
      "|          8.4.74.463|3.6346153846153846|\n",
      "|          8.4.81.558|3.5348837209302326|\n",
      "|          8.9.24.632|               3.5|\n",
      "|          8.8.94.566|               3.5|\n",
      "|           8.3.0.681|               3.5|\n",
      "|          8.6.52.916|               3.5|\n",
      "|          8.4.50.644|               3.5|\n",
      "|          8.4.80.793|               3.4|\n",
      "|             1.2.5.3|3.3333333333333335|\n",
      "|          8.4.82.664|3.2816901408450705|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gruparea recenziilor pe scoruri și calcularea numărului de recenzii utile \n",
    "useful_reviews = df_clean.groupBy(\"score\").agg(count(\"thumbsUpCount\").alias(\"useful_reviews\")) \n",
    "# Afișarea recenziilor utile pe scoruri \n",
    "useful_reviews.orderBy(desc(\"useful_reviews\")).show() \n",
    "# Gruparea recenziilor pe versiuni și calcularea scorului mediu \n",
    "version_score = df_clean.groupBy(\"reviewCreatedVersion\").agg(avg(\"score\").alias(\"average_score\")) \n",
    "# Afișarea scorului mediu pe versiuni \n",
    "version_score.orderBy(desc(\"average_score\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82d3d-2fdc-47ae-9f58-2a43a39ac128",
   "metadata": {},
   "source": [
    "# 3. Aplicarea a cel puțin două metode ML <a name=\"aplicarea\"></a>\r\n",
    "\r\n",
    "În această secțiune, voi aplica două metode de învățare automată folosind Spark MLlib: clasificarea sentimentului recenziilor și regresia pentru a prezice numărul de recenzii utile. Voi descrie problema, justificarea alegerii metodei, explicarea soluției și evaluarea fiecărei metode.\r\n",
    "\r\n",
    "## 3.1 Clasificarea Sentimentului Recenziilor\r\n",
    "\r\n",
    "### a. Enunțul problemei\r\n",
    "\r\n",
    "Problema este de a clasifica recenziile utilizatorilor pentru aplicația Spotify ca fiind pozitive sau negative pe baza scorului oferit. Voi considera recenziile cu scoruri de 4 și 5 ca fiind pozitive și cele cu scoruri de 1, 2 și 3 ca fiind negative.\r\n",
    "\r\n",
    "### Justificarea alegerii metodei\r\n",
    "\r\n",
    "Am ales metoda de clasificare logistică deoarece este eficientă pentru problemele binare și poate oferi o bună interpretabilitate a rezultatelor. Logistic Regression este bine adaptată pentru această problemă datorită naturii binare a etichetei noastre (pozitiv/negativ).\r\n",
    "\r\n",
    "### Explicarea soluției\r\n",
    "\r\n",
    "Voi folosi Spark MLlib pentru a construi un pipeline de procesare a textului și pentru a antrena un model de clasificare logistică. Pipeline-ul va include tokenizarea, eliminarea cuvintelor comune (stop words), conversia textului în vectori de frecvență a termenilor (TF) și calcularea TF-IDF, urmate de aplicarea regresiei logistice.\r\n",
    "\r\n",
    "### b. Aplicarea și evaluarea metodei\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f73785-238e-44ee-aff4-b0b4574ddeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC Curve (AUC): 0.8854976201483787\n",
      "+--------------------+--------------------+----------+-----+\n",
      "|       clean_content|         probability|prediction|label|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "|I love using spot...|[0.11314725935005...|       1.0|    1|\n",
      "|I love my premium...|[0.23074400965238...|       1.0|    1|\n",
      "|The fact that the...|[0.98632583844751...|       0.0|    0|\n",
      "|Huge issue with t...|[0.15691094324704...|       1.0|    1|\n",
      "|After several upd...|[0.71191757889934...|       0.0|    0|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "# Tokenizarea textului recenziilor\n",
    "tokenizer = Tokenizer(inputCol=\"clean_content\", outputCol=\"words\")\n",
    "# Eliminarea cuvintelor comune (stop words)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Convertirea textului în vectori de frecvență a termenilor\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "# Calcularea TF-IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "# Configurarea etichetei pentru clasificare\n",
    "df_clean = df_clean.withColumn(\"label\", (col(\"score\") >= 4).cast(\"int\"))\n",
    "# Crearea modelului de regresie logistică\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "# Crearea pipeline-ului\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "# Împărțirea setului de date în date de antrenament și date de test\n",
    "(trainingData, testData) = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
    "# Antrenarea modelului\n",
    "model = pipeline.fit(trainingData)\n",
    "# Evaluarea modelului pe datele de test\n",
    "predictions = model.transform(testData)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "# Calcularea AUC (area under the curve)\n",
    "auc = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n",
    "print(f\"Area Under ROC Curve (AUC): {auc}\")\n",
    "# Afișarea primelor predicții\n",
    "predictions.select(\"clean_content\", \"probability\", \"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b614b0-7921-4e6f-ad4f-4ee5300af255",
   "metadata": {},
   "source": [
    "### Evaluarea metodei\r\n",
    "AUC (area under the ROC curve) este o măsură utilizată pentru a evalua performanța modelului de clasificare. Un AUC apropiat de 1 indică un model bun, în timp ce un AUC apropiat de 0.5 indică un model care nu este mai bun decât ghicitul aleatoriu metodei\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb72da-e92f-45e9-8473-56bbe0aefd13",
   "metadata": {},
   "source": [
    "## 3.2 Predicția Numărului de Recenzii Utile (Regresie)\n",
    "### a. Enunțul problemei\n",
    "Problema este de a prezice numărul de recenzii utile (thumbsUpCount) pe baza conținutului recenziilor și a altor atribute. Aceasta este o problemă de regresie, deoarece trebuie să prezicem o valoare numerică continuă.\n",
    "### Justificarea alegerii metodei\n",
    "Am ales metoda de regresie liniară deoarece este simplă și eficientă pentru problemele de regresie. Linear Regression poate oferi o interpretare directă a relației dintre caracteristicile de intrare și valoarea de ieșire.\n",
    "### Explicarea soluției\n",
    "Voi folosi Spark MLlib pentru a construi un pipeline de procesare a textului și pentru a antrena un model de regresie liniară. Pipeline-ul va include aceleași etape de preprocesare a textului (tokenizare, eliminare stop words, TF-IDF) urmate de aplicarea regresiei liniare.\n",
    "### b. Aplicarea și evaluarea metodei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857b8fc9-eca8-434e-bb83-abaef05f7f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 122.3070248228727\n",
      "+--------------------+-------------+-------------------+\n",
      "|       clean_content|thumbsUpCount|         prediction|\n",
      "+--------------------+-------------+-------------------+\n",
      "|I love using spot...|            0|-5.7457375333182465|\n",
      "|I love my premium...|            0|  -8.12011514820541|\n",
      "|The fact that the...|           13| 44.790924910877195|\n",
      "|Huge issue with t...|            2| -7.359868963862047|\n",
      "|After several upd...|            0|  12.35054337764135|\n",
      "+--------------------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, when, length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Curățarea valorilor non-numerice din coloana \"thumbsUpCount\"\n",
    "df_clean = df_clean.withColumn(\"thumbsUpCount\", regexp_replace(col(\"thumbsUpCount\"), \"[^0-9]\", \"\"))\n",
    "\n",
    "# Înlocuirea șirurilor de caractere goale cu '0'\n",
    "df_clean = df_clean.withColumn(\"thumbsUpCount\", when(col(\"thumbsUpCount\") == \"\", \"0\").otherwise(col(\"thumbsUpCount\")))\n",
    "\n",
    "# Convertirea coloanei \"thumbsUpCount\" la tip numeric\n",
    "df_clean = df_clean.withColumn(\"thumbsUpCount\", col(\"thumbsUpCount\").cast(\"int\"))\n",
    "\n",
    "# Eliminarea valorilor lipsă sau NaN în coloana \"thumbsUpCount\" și \"clean_content\"\n",
    "df_clean = df_clean.na.drop(subset=[\"thumbsUpCount\", \"clean_content\"])\n",
    "\n",
    "# Adăugarea lungimii recenziei ca o caracteristică suplimentară\n",
    "df_clean = df_clean.withColumn(\"review_length\", length(col(\"clean_content\")))\n",
    "\n",
    "# Tokenizarea textului recenziilor \n",
    "tokenizer = Tokenizer(inputCol=\"clean_content\", outputCol=\"words\")\n",
    "\n",
    "# Eliminarea cuvintelor comune (stop words)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Convertirea textului în vectori de frecvență a termenilor \n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "\n",
    "# Calcularea TF-IDF \n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Vectorizarea caracteristicilor (inclusiv lungimea recenziei)\n",
    "assembler = VectorAssembler(inputCols=[\"features\", \"review_length\"], outputCol=\"final_features\")\n",
    "\n",
    "# Crearea modelului de regresie liniară\n",
    "lr_regression = LinearRegression(featuresCol=\"final_features\", labelCol=\"thumbsUpCount\")\n",
    "\n",
    "# Crearea pipeline-ului\n",
    "pipeline_regression = Pipeline(stages=[tokenizer, remover, hashingTF, idf, assembler, lr_regression])\n",
    "\n",
    "# Împărțirea setului de date în date de antrenament și date de test\n",
    "(trainingData, testData) = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Antrenarea modelului\n",
    "model_regression = pipeline_regression.fit(trainingData)\n",
    "\n",
    "# Evaluarea modelului pe datele de test\n",
    "predictions_regression = model_regression.transform(testData)\n",
    "\n",
    "# Evaluarea modelului folosind RMSE (root mean squared error)\n",
    "evaluator_regression = RegressionEvaluator(labelCol=\"thumbsUpCount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_regression.evaluate(predictions_regression)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Afișarea primelor predicții\n",
    "predictions_regression.select(\"clean_content\", \"thumbsUpCount\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add8d07-b607-4fe5-a275-6010309bbdfe",
   "metadata": {},
   "source": [
    "### Evaluarea metodei\r\n",
    "RMSE (root mean squared error) este o măsură utilizată pentru a evalua performanța unui model de regresie. Un RMSE mai mic indică un model mai bun, deoarece erorile de predicție sunt mai mici.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ecaf1-d067-4c96-ae03-4fbec574c977",
   "metadata": {},
   "source": [
    "## 3.3 Gruparea Recenziilor Utilizatorilor folosind K-means Clustering\n",
    "### a. Enunțul Problemei\n",
    "Problema constă în identificarea grupurilor de recenzii similare bazate pe conținutul acestora. Scopul este de a descoperi teme și modele recurente în recenziile utilizatorilor pentru aplicația Spotify, fără a dispune de etichete predefinite (clustering nesupravegheat).\n",
    "\n",
    "### Justificarea Alegerii Metodei\n",
    "Am optat pentru K-means clustering datorită eficienței și popularității sale în rezolvarea problemelor de clustering nesupravegheat. Algoritmul K-means este adecvat pentru identificarea subgrupurilor în seturi mari de date și poate facilita descoperirea de noi perspective și teme în recenziile utilizatorilor.\n",
    "\n",
    "### Explicarea Soluției\n",
    "Voi utiliza Spark MLlib pentru a construi un pipeline de preprocesare a textului și pentru a aplica algoritmul K-means. Pipeline-ul va include etapele de tokenizare, eliminare a cuvintelor comune (stop words), conversie a textului în vectori de frecvență a termenilor (TF), calcularea TF-IDF, urmate de aplicarea algoritmului K-means pentru gruparea recenziilor.\n",
    "\n",
    "### b. Aplicarea și Evaluarea Metodei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a28aec7-ac96-4aee-b89f-f965fe2e6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.0628982526916374\n",
      "+--------------------+----------+\n",
      "|       clean_content|prediction|\n",
      "+--------------------+----------+\n",
      "|            Its good|         0|\n",
      "|I love this app s...|         1|\n",
      "|             Perfect|         0|\n",
      "|Best all around m...|         0|\n",
      "|Are yall fr gatek...|         0|\n",
      "|            Loved it|         0|\n",
      "|The app is good b...|         0|\n",
      "|       excellent app|         0|\n",
      "| I like this spotify|         0|\n",
      "|        Eat the rich|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, to_date\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Tokenizarea textului recenziilor \n",
    "tokenizer = Tokenizer(inputCol=\"clean_content\", outputCol=\"words\")\n",
    "# Eliminarea cuvintelor comune (stop words)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Convertirea textului în vectori de frecvență a termenilor \n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "# Calcularea TF-IDF \n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "# Aplicarea K-means clustering\n",
    "kmeans = KMeans(featuresCol=\"features\", k=5, seed=1234)  # k este numărul de clustere\n",
    "# Crearea pipeline-ului\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, kmeans])\n",
    "# Antrenarea modelului\n",
    "model = pipeline.fit(df_clean)\n",
    "# Aplicarea modelului pentru a obține predicțiile\n",
    "predictions = model.transform(df_clean)\n",
    "# Evaluarea clusteringului folosind Silhouette Score\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", metricName=\"silhouette\")\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "# Afișarea primelor predicții\n",
    "predictions.select(\"clean_content\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6985d-903d-4341-afc3-4384fc8734c2",
   "metadata": {},
   "source": [
    "### Evaluarea Metodei\n",
    "1) Silhouette Score: Un scor Silhouette mai mare indică o mai bună separare între clustere. Acesta variază între -1 și 1, unde valori mai mari sunt mai bune.\n",
    "2) Vizualizarea Clusterele: Putem folosi vizualizări (de exemplu, t-SNE sau PCA) pentru a vizualiza cum au fost grupate recenziile în funcție de conținut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0b7e9-7d69-489f-875f-933d79793845",
   "metadata": {},
   "source": [
    "# 4. Utilizarea unui Data Pipeline <a name=\"utilizarea\"></a>\n",
    "\n",
    "Un Data Pipeline în Apache Spark permite automatizarea proceselor de preprocesare, transformare și aplicare a modelelor de învățare automată. În acest proiect, voi crea un pipeline care include toate etapele necesare pentru clasificarea sentimentului recenziilor Spotify.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1f3c3-d16b-4fc8-92ee-929fa202ab9c",
   "metadata": {},
   "source": [
    "Pipeline-ul este creat și utilizat în acest cod pentru a automatiza întregul proces de preprocesare a textului și aplicarea algoritmului \n",
    "K-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16993b45-19d8-44fe-801d-1df3013af000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.0628982526916374\n",
      "+--------------------+----------+\n",
      "|       clean_content|prediction|\n",
      "+--------------------+----------+\n",
      "|            Its good|         0|\n",
      "|I love this app s...|         1|\n",
      "|             Perfect|         0|\n",
      "|Best all around m...|         0|\n",
      "|Are yall fr gatek...|         0|\n",
      "|            Loved it|         0|\n",
      "|The app is good b...|         0|\n",
      "|       excellent app|         0|\n",
      "| I like this spotify|         0|\n",
      "|        Eat the rich|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, to_date\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "# Tokenizarea textului recenziilor \n",
    "tokenizer = Tokenizer(inputCol=\"clean_content\", outputCol=\"words\")\n",
    "# Eliminarea cuvintelor comune (stop words)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Convertirea textului în vectori de frecvență a termenilor \n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "# Calcularea TF-IDF \n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "# Aplicarea K-means clustering\n",
    "kmeans = KMeans(featuresCol=\"features\", k=5, seed=1234)  # k este numărul de clustere\n",
    "# Crearea pipeline-ului\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, kmeans])\n",
    "# Antrenarea modelului\n",
    "model = pipeline.fit(df_clean)\n",
    "# Aplicarea modelului pentru a obține predicțiile\n",
    "predictions = model.transform(df_clean)\n",
    "# Evaluarea clusteringului folosind Silhouette Score\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", metricName=\"silhouette\")\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "# Afișarea primelor predicții\n",
    "predictions.select(\"clean_content\", \"prediction\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
